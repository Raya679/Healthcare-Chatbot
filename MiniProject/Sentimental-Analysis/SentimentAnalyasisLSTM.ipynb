{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvFunQag7VbP",
        "outputId": "c9a6df08-2fa3-4b27-9396-f8a719185fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb = pd.read_csv('/content/drive/MyDrive/IMDB_Dataset.csv')\n",
        "imdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-CiVG-Gy7lS-",
        "outputId": "36bd866e-7e3d-4644-9399-106fdb1e89a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8555d272-cdf4-4042-ac5b-008badd13dd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8555d272-cdf4-4042-ac5b-008badd13dd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8555d272-cdf4-4042-ac5b-008badd13dd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8555d272-cdf4-4042-ac5b-008badd13dd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd8cb04e-320c-4dea-b1b6-e0c828dbf48b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd8cb04e-320c-4dea-b1b6-e0c828dbf48b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd8cb04e-320c-4dea-b1b6-e0c828dbf48b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = imdb['review'].values,imdb['sentiment'].values\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
        "print(f'shape of train data is {X_train.shape}')\n",
        "print(f'shape of test data is {X_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuM41Kd_7y7N",
        "outputId": "b49d6366-411b-4ee0-bd02-f44d22d1e05f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (37500,)\n",
            "shape of test data is (12500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def tokenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "\n",
        "    freq = Counter(word_list)\n",
        "    word_freq = sorted(freq,key=freq.get,reverse=True)[:1000]\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(word_freq)}\n",
        "\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess(word)] for word in sent.lower().split()\n",
        "                                     if preprocess(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess(word)] for word in sent.lower().split()\n",
        "                                    if preprocess(word) in onehot_dict.keys()])\n",
        "\n",
        "    encoded_train = [1 if label =='positive' else 0 for label in y_train]\n",
        "    encoded_test = [1 if label =='positive' else 0 for label in y_val]\n",
        "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
      ],
      "metadata": {
        "id": "XF74d2om7z4O"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train,X_test,y_test,vocab = tokenize(X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A56BeDAM8DU_",
        "outputId": "fc75453d-a156-4b84-b7f7-c4db41c9c89d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-afc815a23ffd>:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxaTBQl-8NFg",
        "outputId": "50da67a1-69bb-44a3-bc9d-b70a3d04be2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 1000\n",
            "{'br': 1, 'movie': 2, 'film': 3, 'one': 4, 'like': 5, 'good': 6, 'even': 7, 'would': 8, 'time': 9, 'really': 10, 'see': 11, 'story': 12, 'well': 13, 'much': 14, 'get': 15, 'great': 16, 'also': 17, 'bad': 18, 'people': 19, 'first': 20, 'dont': 21, 'made': 22, 'films': 23, 'movies': 24, 'make': 25, 'could': 26, 'way': 27, 'characters': 28, 'think': 29, 'watch': 30, 'many': 31, 'seen': 32, 'character': 33, 'two': 34, 'never': 35, 'love': 36, 'acting': 37, 'best': 38, 'plot': 39, 'little': 40, 'know': 41, 'show': 42, 'ever': 43, 'life': 44, 'better': 45, 'still': 46, 'scene': 47, 'say': 48, 'end': 49, 'man': 50, 'scenes': 51, 'something': 52, 'go': 53, 'im': 54, 'back': 55, 'real': 56, 'watching': 57, 'thing': 58, 'doesnt': 59, 'actors': 60, 'didnt': 61, 'years': 62, 'actually': 63, 'another': 64, 'funny': 65, 'though': 66, 'makes': 67, 'nothing': 68, 'find': 69, 'look': 70, 'work': 71, 'going': 72, 'every': 73, 'lot': 74, 'new': 75, 'old': 76, 'part': 77, 'us': 78, 'cant': 79, 'director': 80, 'thats': 81, 'want': 82, 'pretty': 83, 'things': 84, 'cast': 85, 'quite': 86, 'seems': 87, 'around': 88, 'got': 89, 'take': 90, 'young': 91, 'fact': 92, 'world': 93, 'big': 94, 'enough': 95, 'however': 96, 'thought': 97, 'horror': 98, 'ive': 99, 'give': 100, 'may': 101, 'without': 102, 'isnt': 103, 'long': 104, 'gets': 105, 'always': 106, 'saw': 107, 'come': 108, 'music': 109, 'right': 110, 'almost': 111, 'theres': 112, 'must': 113, 'series': 114, 'original': 115, 'times': 116, 'whole': 117, 'role': 118, 'least': 119, 'comedy': 120, 'action': 121, 'point': 122, 'interesting': 123, 'guy': 124, 'bit': 125, 'done': 126, 'script': 127, 'hes': 128, 'far': 129, 'feel': 130, 'last': 131, 'might': 132, 'since': 133, 'minutes': 134, 'anything': 135, 'probably': 136, 'family': 137, 'performance': 138, 'kind': 139, 'tv': 140, 'yet': 141, 'worst': 142, 'rather': 143, 'fun': 144, 'away': 145, 'sure': 146, 'played': 147, 'anyone': 148, 'found': 149, 'making': 150, 'girl': 151, 'although': 152, 'shows': 153, 'believe': 154, 'trying': 155, 'especially': 156, 'woman': 157, 'course': 158, 'everything': 159, 'goes': 160, 'comes': 161, 'put': 162, 'hard': 163, 'dvd': 164, 'day': 165, 'looking': 166, 'worth': 167, 'different': 168, 'main': 169, 'maybe': 170, 'wasnt': 171, 'book': 172, 'place': 173, 'looks': 174, 'set': 175, 'effects': 176, 'play': 177, 'ending': 178, 'watched': 179, 'sense': 180, 'three': 181, 'screen': 182, 'reason': 183, 'money': 184, 'someone': 185, 'job': 186, 'plays': 187, 'together': 188, 'seem': 189, 'true': 190, 'takes': 191, 'actor': 192, 'said': 193, 'instead': 194, 'everyone': 195, 'special': 196, 'john': 197, 'later': 198, 'american': 199, 'audience': 200, 'beautiful': 201, 'seeing': 202, 'war': 203, 'version': 204, 'left': 205, 'excellent': 206, 'night': 207, 'idea': 208, 'shot': 209, 'completely': 210, 'black': 211, 'fan': 212, 'youre': 213, 'high': 214, 'house': 215, 'poor': 216, 'used': 217, 'wife': 218, 'simply': 219, 'death': 220, 'kids': 221, 'else': 222, 'nice': 223, 'along': 224, 'help': 225, 'read': 226, 'friends': 227, 'year': 228, 'star': 229, 'second': 230, 'short': 231, 'half': 232, 'try': 233, 'enjoy': 234, 'use': 235, 'mind': 236, 'given': 237, 'men': 238, 'need': 239, 'home': 240, 'boring': 241, 'less': 242, 'either': 243, 'performances': 244, 'rest': 245, 'classic': 246, 'production': 247, 'couple': 248, 'truly': 249, 'stupid': 250, 'recommend': 251, 'line': 252, 'next': 253, 'dead': 254, 'start': 255, 'women': 256, 'wrong': 257, 'tell': 258, 'let': 259, 'father': 260, 'came': 261, 'getting': 262, 'hollywood': 263, 'understand': 264, 'full': 265, 'remember': 266, 'camera': 267, 'terrible': 268, 'perhaps': 269, 'awful': 270, 'keep': 271, 'wonderful': 272, 'others': 273, 'sex': 274, 'mean': 275, 'school': 276, 'playing': 277, 'moments': 278, 'name': 279, 'early': 280, 'gives': 281, 'episode': 282, 'definitely': 283, 'top': 284, 'small': 285, 'often': 286, 'video': 287, 'human': 288, 'piece': 289, 'budget': 290, 'couldnt': 291, 'lines': 292, 'went': 293, 'perfect': 294, 'absolutely': 295, 'dialogue': 296, 'person': 297, 'finally': 298, 'guys': 299, 'head': 300, 'certainly': 301, 'sort': 302, 'liked': 303, 'case': 304, 'become': 305, 'title': 306, 'felt': 307, 'hope': 308, 'entire': 309, 'stars': 310, 'face': 311, 'worse': 312, 'loved': 313, 'written': 314, 'overall': 315, 'lost': 316, 'style': 317, 'supposed': 318, 'yes': 319, 'waste': 320, 'live': 321, 'picture': 322, 'oh': 323, 'several': 324, 'entertaining': 325, 'mr': 326, 'shes': 327, 'problem': 328, 'based': 329, 'friend': 330, 'sound': 331, 'totally': 332, 'beginning': 333, 'dark': 334, 'mother': 335, 'boy': 336, 'laugh': 337, 'despite': 338, 'seemed': 339, 'final': 340, 'wanted': 341, 'humor': 342, 'care': 343, 'fans': 344, 'becomes': 345, 'guess': 346, 'cinema': 347, 'lead': 348, 'youll': 349, 'direction': 350, 'able': 351, 'already': 352, 'example': 353, 'wont': 354, 'id': 355, 'throughout': 356, 'white': 357, 'lives': 358, 'called': 359, 'game': 360, 'evil': 361, 'turn': 362, 'unfortunately': 363, 'children': 364, 'drama': 365, 'wants': 366, 'low': 367, 'michael': 368, 'horrible': 369, 'theyre': 370, 'girls': 371, 'days': 372, 'fine': 373, 'works': 374, 'writing': 375, 'tries': 376, 'history': 377, 'quality': 378, 'amazing': 379, 'enjoyed': 380, 'gave': 381, 'killer': 382, 'past': 383, 'parts': 384, 'kill': 385, 'son': 386, 'act': 387, 'favorite': 388, 'car': 389, 'turns': 390, 'brilliant': 391, 'town': 392, 'obviously': 393, 'expect': 394, 'run': 395, 'behind': 396, 'side': 397, 'flick': 398, 'stuff': 399, 'sometimes': 400, 'matter': 401, 'starts': 402, 'ones': 403, 'viewer': 404, 'decent': 405, 'eyes': 406, 'directed': 407, 'took': 408, 'thinking': 409, 'soon': 410, 'says': 411, 'city': 412, 'ill': 413, 'highly': 414, 'late': 415, 'killed': 416, 'kid': 417, 'happens': 418, 'group': 419, 'fight': 420, 'extremely': 421, 'except': 422, 'genre': 423, 'hell': 424, 'actress': 425, 'heard': 426, 'art': 427, 'feeling': 428, 'heart': 429, 'leave': 430, 'lack': 431, 'child': 432, 'coming': 433, 'police': 434, 'hour': 435, 'stories': 436, 'blood': 437, 'cannot': 438, 'told': 439, 'close': 440, 'involved': 441, 'looked': 442, 'save': 443, 'strong': 444, 'wonder': 445, 'wouldnt': 446, 'etc': 447, 'moment': 448, 'chance': 449, 'hand': 450, 'ok': 451, 'score': 452, 'type': 453, 'taken': 454, 'particularly': 455, 'complete': 456, 'attempt': 457, 'james': 458, 'happened': 459, 'experience': 460, 'serious': 461, 'including': 462, 'god': 463, 'living': 464, 'violence': 465, 'stop': 466, 'obvious': 467, 'hilarious': 468, 'simple': 469, 'itbr': 470, 'voice': 471, 'daughter': 472, 'robert': 473, 'opening': 474, 'cool': 475, 'roles': 476, 'anyway': 477, 'number': 478, 'please': 479, 'huge': 480, 'across': 481, 'david': 482, 'murder': 483, 'exactly': 484, 'shown': 485, 'saying': 486, 'happen': 487, 'lets': 488, 'ago': 489, 'interest': 490, 'known': 491, 'song': 492, 'usually': 493, 'cinematography': 494, 'released': 495, 'jokes': 496, 'alone': 497, 'slow': 498, 'annoying': 499, 'whose': 500, 'english': 501, 'reality': 502, 'seriously': 503, 'crap': 504, 'major': 505, 'hours': 506, 'none': 507, 'hit': 508, 'relationship': 509, 'wish': 510, 'career': 511, 'shots': 512, 'call': 513, 'today': 514, 'order': 515, 'hero': 516, 'running': 517, 'possible': 518, 'cut': 519, 'talent': 520, 'sad': 521, 'gore': 522, 'documentary': 523, 'ridiculous': 524, 'started': 525, 'mostly': 526, 'female': 527, 'ends': 528, 'usual': 529, 'somewhat': 530, 'beyond': 531, 'knows': 532, 'brother': 533, 'silly': 534, 'important': 535, 'novel': 536, 'knew': 537, 'apparently': 538, 'scary': 539, 'power': 540, 'view': 541, 'change': 542, 'word': 543, 'turned': 544, 'problems': 545, 'taking': 546, 'age': 547, 'whats': 548, 'rating': 549, 'opinion': 550, 'finds': 551, 'arent': 552, 'due': 553, 'directors': 554, 'words': 555, 'body': 556, 'four': 557, 'strange': 558, 'attention': 559, 'clearly': 560, 'room': 561, 'basically': 562, 'local': 563, 'single': 564, 'talking': 565, 'episodes': 566, 'moviebr': 567, 'upon': 568, 'level': 569, 'disappointed': 570, 'country': 571, 'modern': 572, 'jack': 573, 'husband': 574, 'light': 575, 'cheap': 576, 'sequence': 577, 'musical': 578, 'television': 579, 'happy': 580, 'tells': 581, 'british': 582, 'talk': 583, 'easily': 584, 'whether': 585, 'bring': 586, 'falls': 587, 'predictable': 588, 'add': 589, 'events': 590, 'miss': 591, 'supporting': 592, 'havent': 593, 'lots': 594, 'george': 595, 'songs': 596, 'mention': 597, 'needs': 598, 'sets': 599, 'giving': 600, 'earth': 601, 'soundtrack': 602, 'team': 603, 'review': 604, 'bunch': 605, 'appears': 606, 'similar': 607, 'romantic': 608, 'future': 609, 'five': 610, 'dialog': 611, 'surprised': 612, 'viewers': 613, 'enjoyable': 614, 'filmbr': 615, 'comic': 616, 'among': 617, 'theme': 618, 'french': 619, 'ten': 620, 'typical': 621, 'entertainment': 622, 'tried': 623, 'within': 624, 'parents': 625, 'storyline': 626, 'hate': 627, 'moving': 628, 'clear': 629, 'dull': 630, 'fall': 631, 'space': 632, 'ways': 633, 'filmed': 634, 'named': 635, 'message': 636, 'certain': 637, 'middle': 638, 'sorry': 639, 'showing': 640, 'king': 641, 'using': 642, 'thriller': 643, 'easy': 644, 'effort': 645, 'feels': 646, 'nearly': 647, 'sequel': 648, 'writer': 649, 'buy': 650, 'near': 651, 'release': 652, 'richard': 653, 'suspense': 654, 'avoid': 655, 'gone': 656, 'theater': 657, 'greatest': 658, 'actual': 659, 'mystery': 660, 'means': 661, 'deal': 662, 'stay': 663, 'rock': 664, 'kept': 665, 'comments': 666, 'lady': 667, 'straight': 668, 'working': 669, 'elements': 670, 'dr': 671, 'peter': 672, 'sister': 673, 'general': 674, 'editing': 675, 'subject': 676, 'fantastic': 677, 'famous': 678, 'brought': 679, 'minute': 680, 'viewing': 681, 'feature': 682, 'monster': 683, 'points': 684, 'imagine': 685, 'doubt': 686, 'form': 687, 'youve': 688, 'die': 689, 'okay': 690, 'check': 691, 'th': 692, 'move': 693, 'class': 694, 'somehow': 695, 'material': 696, 'realistic': 697, 'sit': 698, 'boys': 699, 'tom': 700, 'forget': 701, 'tale': 702, 'animation': 703, 'paul': 704, 'killing': 705, 'leads': 706, 'hear': 707, 'dog': 708, 'rent': 709, 'begins': 710, 'reviews': 711, 'whos': 712, 'learn': 713, 'red': 714, 'expected': 715, 'surprise': 716, 'particular': 717, 'weak': 718, 'decided': 719, 'sequences': 720, 'atmosphere': 721, 'eventually': 722, 'period': 723, 'figure': 724, 'indeed': 725, 'begin': 726, 'eye': 727, 'believable': 728, 'york': 729, 'poorly': 730, 'crime': 731, 'fast': 732, 'shame': 733, 'stand': 734, 'season': 735, 'deep': 736, 'difficult': 737, 'leaves': 738, 'premise': 739, 'lame': 740, 'emotional': 741, 'follow': 742, 'meet': 743, 'average': 744, 'whatever': 745, 'dance': 746, 'reading': 747, 'oscar': 748, 'memorable': 749, 'superb': 750, 'crew': 751, 'truth': 752, 'became': 753, 'third': 754, 'needed': 755, 'forced': 756, 'situation': 757, 'romance': 758, 'keeps': 759, 'note': 760, 'footage': 761, 'writers': 762, 'otherwise': 763, 'possibly': 764, 'scifi': 765, 'open': 766, 'features': 767, 'hot': 768, 'question': 769, 'plus': 770, 'total': 771, 'towards': 772, 'meets': 773, 'unless': 774, 'filmmakers': 775, 'wait': 776, 'western': 777, 'inside': 778, 'interested': 779, 'personal': 780, 'perfectly': 781, 'beauty': 782, 'sexual': 783, 'de': 784, 'badly': 785, 'credits': 786, 'hands': 787, 'sounds': 788, 'previous': 789, 'doctor': 790, 'write': 791, 'result': 792, 'earlier': 793, 'weird': 794, 'cheesy': 795, 'japanese': 796, 'island': 797, 'incredibly': 798, 'laughs': 799, 'box': 800, 'b': 801, 'quickly': 802, 'comment': 803, 'gay': 804, 'society': 805, 'street': 806, 'stage': 807, 'copy': 808, 'screenplay': 809, 'imdb': 810, 'appear': 811, 'nature': 812, 'fairly': 813, 'realize': 814, 'male': 815, 'background': 816, 'setting': 817, 'air': 818, 'various': 819, 'portrayed': 820, 'plenty': 821, 'brings': 822, 'worked': 823, 'lee': 824, 'crazy': 825, 'unique': 826, 'older': 827, 'free': 828, 'mess': 829, 'america': 830, 'effect': 831, 'battle': 832, 'admit': 833, 'spent': 834, 'following': 835, 'powerful': 836, 'creepy': 837, 'apart': 838, 'masterpiece': 839, 'ask': 840, 'dramatic': 841, 'joe': 842, 'development': 843, 'fire': 844, 'forward': 845, 'front': 846, 'joke': 847, 'success': 848, 'ideas': 849, 'directing': 850, 'business': 851, 'wasted': 852, 'remake': 853, 'meant': 854, 'rich': 855, 'leading': 856, 'outside': 857, 'fails': 858, 'expecting': 859, 'mark': 860, 'dream': 861, 'baby': 862, 'cover': 863, 'match': 864, 'acted': 865, 'pay': 866, 'unlike': 867, 'present': 868, 'return': 869, 'manages': 870, 'members': 871, 'deserves': 872, 'hardly': 873, 'reasons': 874, 'attempts': 875, 'la': 876, 'brothers': 877, 'caught': 878, 'cop': 879, 'william': 880, 'bill': 881, 'political': 882, 'twist': 883, 'missing': 884, 'party': 885, 'agree': 886, 'potential': 887, 'recently': 888, 'dumb': 889, 'escape': 890, 'large': 891, 'water': 892, 'break': 893, 'create': 894, 'girlfriend': 895, 'waiting': 896, 'talented': 897, 'pure': 898, 'laughing': 899, 'cause': 900, 'ended': 901, 'zombie': 902, 'telling': 903, 'visual': 904, 'odd': 905, 'fighting': 906, 'missed': 907, 'secret': 908, 'plain': 909, 'created': 910, 'married': 911, 'sadly': 912, 'gun': 913, 'slightly': 914, 'company': 915, 'considering': 916, 'clever': 917, 'hold': 918, 'pace': 919, 'cartoon': 920, 'disney': 921, 'villain': 922, 'german': 923, 'decides': 924, 'entirely': 925, 'casting': 926, 'sees': 927, 'incredible': 928, 'familiar': 929, 'nudity': 930, 'mentioned': 931, 'follows': 932, 'tension': 933, 'speak': 934, 'office': 935, 'credit': 936, 'sweet': 937, 'wrote': 938, 'amount': 939, 'italian': 940, 'intelligent': 941, 'popular': 942, 'uses': 943, 'neither': 944, 'public': 945, 'fit': 946, 'van': 947, 'suddenly': 948, 'biggest': 949, 'common': 950, 'flat': 951, 'produced': 952, 'train': 953, 'cute': 954, 'scott': 955, 'died': 956, 'recent': 957, 'language': 958, 'moves': 959, 'compared': 960, 'store': 961, 'fantasy': 962, 'producers': 963, 'longer': 964, 'state': 965, 'appreciate': 966, 'concept': 967, 'rate': 968, 'ultimately': 969, 'portrayal': 970, 'list': 971, 'social': 972, 'exciting': 973, 'band': 974, 'successful': 975, 'yeah': 976, 'kills': 977, 'spend': 978, 'convincing': 979, 'younger': 980, 'amusing': 981, 'value': 982, 'bored': 983, 'hair': 984, 'former': 985, 'trouble': 986, 'force': 987, 'era': 988, 'bizarre': 989, 'fear': 990, 'audiences': 991, 'decide': 992, 'dancing': 993, 'pathetic': 994, 'effective': 995, 'filled': 996, 'science': 997, 'violent': 998, 'prison': 999, 'jane': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features\n",
        "\n",
        "x_train_pad = padding_(X_train,500)\n",
        "x_test_pad = padding_(X_test,500)"
      ],
      "metadata": {
        "id": "K77uMKe-8nIu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yDJQDXAT9bsx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self,no_layers,vocab_size,output_dim,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(SentimentRNN,self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           num_layers=no_layers, batch_first=True)\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.lin = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,input,hidden):\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        embeds = self.embedding(input)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.lin(out)\n",
        "\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1]\n",
        "\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "s7hp70NF9gmj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 1\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,output_dim,hidden_dim,embedding_dim,drop_prob=0.5)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H173ukOs9uks",
        "outputId": "2e6ae252-43af-4d6e-edae-e62f4d7a4a2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (lin): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "metadata": {
        "id": "7JnLwVeX96fD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 5\n",
        "\n",
        "#training loop\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "\n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    test_h = model.init_hidden(batch_size)\n",
        "    test_losses = []\n",
        "    test_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in test_loader:\n",
        "            test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "            output, test_h = model(inputs, test_h)\n",
        "            test_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "            accuracy = acc(output,labels)\n",
        "            test_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_test_loss = np.mean(test_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_test_acc = test_acc/len(test_loader.dataset)\n",
        "\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} test_loss : {epoch_test_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} test_accuracy : {epoch_test_acc*100}')\n"
      ],
      "metadata": {
        "id": "1dwM2n6p-CNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b64480-5d12-4e77-b648-d9fabb0ce300"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.5169673895637195 test_loss : 0.42572581535577775\n",
            "train_accuracy : 74.53066666666666 test_accuracy : 81.104\n",
            "Epoch 2\n",
            "train_loss : 0.3835217460195223 test_loss : 0.3885291995406151\n",
            "train_accuracy : 83.408 test_accuracy : 83.12\n",
            "Epoch 3\n",
            "train_loss : 0.332069266974926 test_loss : 0.3533663983345032\n",
            "train_accuracy : 85.97333333333333 test_accuracy : 84.19200000000001\n",
            "Epoch 4\n",
            "train_loss : 0.2998346304992835 test_loss : 0.3299584139585495\n",
            "train_accuracy : 87.464 test_accuracy : 85.824\n",
            "Epoch 5\n",
            "train_loss : 0.26592094752192497 test_loss : 0.33927978563308714\n",
            "train_accuracy : 89.19466666666666 test_accuracy : 86.024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "        word_seq = np.array([vocab[preprocess(word)] for word in text.split()\n",
        "                         if preprocess(word) in vocab.keys()])\n",
        "        word_seq = np.expand_dims(word_seq,axis=0)\n",
        "        pad =  torch.from_numpy(padding_(word_seq,500))\n",
        "        batch_size = 1\n",
        "        h = model.init_hidden(batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        output, h = model(pad, h)\n",
        "        return(output.item())"
      ],
      "metadata": {
        "id": "B7K2mUAfBDL7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 6875\n",
        "print(imdb['review'][index])\n",
        "\n",
        "print(f'Actual sentiment is : {imdb[\"sentiment\"][index]}')\n",
        "\n",
        "prediction = predict_text(imdb['review'][index])\n",
        "status = \"positive\" if prediction > 0.5 else \"negative\"\n",
        "print(f'Predicted sentiment is : {status} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSnt2tY0u6Gr",
        "outputId": "7fd302d9-2190-4bba-f1cc-90a9847964b0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I was really looking forward to this show given the quality of the actors and the fact that The Scott brothers were involved. Unfortunately my hopes were dashed! Yet again we are led to believe that the KGB are a group of inept morons who don't have a clue what they are doing. At one point there is a laughable scene where 4 KGB agents couldn't handle one CIA agent. I grow weary of these biased, one sided and completely inaccurate portrayals of the Spy game that went on during the cold war. I find it laughable that the US is incapable of making objective movies about their involvement in WW2 and beyond. Just like the pathetic U-571, where we are led to believe that the US obtained the Enigma machine, again, utterly false.<br /><br />To its credit, \"The Company\" is very well filmed and acted. The locales are also exceptionally well realised. Alfred Molina puts in a great performance as does Keaton (The conflict between them is very well done). I really wanted to like this show and no doubt I will end up watching the other 2 episodes but I really wish that US productions would stop trying to portray their Spies, servicemen etc as supermen who are vastly intellectually and physically superior to anyone else on the planet. It gets old fast and seriously detracts from the plausibility of what could have been a 10/10.<br /><br />S\n",
            "Actual sentiment is : negative\n",
            "Predicted sentiment is : negative \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQY-Ncj1u9K0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}