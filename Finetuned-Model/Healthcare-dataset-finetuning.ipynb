{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqqq pip\n!pip install -qqq bitsandbytes==0.39.0\n!pip install -qqq torch==2.0.1\n!pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc\n!pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f\n!pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71\n!pip install -qqq datasets==2.12.0\n!pip install -qqq loralib==0.1.1\n!pip install -qqq einops==0.6.1 ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-29T05:28:47.730817Z","iopub.execute_input":"2023-10-29T05:28:47.731081Z","iopub.status.idle":"2023-10-29T05:34:39.945605Z","shell.execute_reply.started":"2023-10-29T05:28:47.731057Z","shell.execute_reply":"2023-10-29T05:34:39.944305Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\npathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\npathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport os\nfrom pprint import pprint\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import load_dataset\nfrom huggingface_hub import notebook_login\nfrom peft import (\n    LoraConfig,\n    PeftConfig,\n    PeftModel,\n    get_peft_model,\n    prepare_model_for_kbit_training\n)\nfrom transformers import (\n    AutoConfig,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig\n)\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:34:39.948288Z","iopub.execute_input":"2023-10-29T05:34:39.948817Z","iopub.status.idle":"2023-10-29T05:34:57.928170Z","shell.execute_reply.started":"2023-10-29T05:34:39.948771Z","shell.execute_reply":"2023-10-29T05:34:57.927264Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL_NAME = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    quantization_config=bnb_config\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:34:57.953832Z","iopub.execute_input":"2023-10-29T05:34:57.954096Z","iopub.status.idle":"2023-10-29T05:39:50.076139Z","shell.execute_reply.started":"2023-10-29T05:34:57.954073Z","shell.execute_reply":"2023-10-29T05:39:50.075325Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"626070c2359442de8c81119aa878c1df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)figuration_falcon.py:   0%|          | 0.00/6.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76518a1b36194156a2fc6a2969a2cf4b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- configuration_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)n/modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"067391f32cee448cadf00725e91f60ae"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- modeling_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)fetensors.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"756dccf9ee4f47ed8433407333412efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88607049049c4b76bdfc520e60dde101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed1655b86d1244fea46c873903839fbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011ee0e04d8e4b43a232d7b77a832c79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987f4db61cca40a0bbf1c82479882f0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94725de47e1147c195c9ac938a648118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8ddc8cdbef43b189ec7a2fa5be20e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44915e06722e414986e1216e435181ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc1a92e441934456a778d716a17a6b68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052a6369888b437d8391932ac8070808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12936f333c9e4c20afc069061142ea98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161b2e068cf14fd4af5e29c9be4b5afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aada7a26f3fc44a984779fb8a84f1285"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b2e5036f9a4fa79e214d3811a7474c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02e018be4c04c48a7f175ff05e48198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3da39fc0e2a49c882a0463049ffafb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00015.safetensors:   0%|          | 0.00/828M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49735e76f74406bb5b9f59826ef72be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37d1491e36f84899a2a69a378eaa5cd7"}},"metadata":{}},{"name":"stderr","text":"Some weights of FalconForCausalLM were not initialized from the model checkpoint at vilsonrodrigues/falcon-7b-instruct-sharded and are newly initialized: ['lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"254a4b9cb43248d8851d4fe9c8ed14e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515c1044000145758a886fa25106b4f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3f36161e8741cea5306d8f739bf398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd7414f1a488407091c753597339995e"}},"metadata":{}}]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n  \"\"\"\n  Prints the number of trainable parameters in the model.\n  \"\"\"\n  trainable_params = 0\n  all_param = 0\n  for _, param in model.named_parameters():\n    all_param += param.numel()\n    if param.requires_grad:\n      trainable_params += param.numel()\n  print(\n      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query_key_value\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\"json\", data_files=\"/kaggle/input/healthcare-dataset-100k/HealthCareMagic-100k.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"train\"][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(data_point):\n  return f\"\"\"\n<human>: {data_point[\"input\"]}\n<assistant>: {data_point[\"output\"]}\n\"\"\".strip()\n\ndef generate_and_tokenize_prompt(data_point):\n  full_prompt = generate_prompt(data_point)\n  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n  return tokenized_full_prompt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n      per_device_train_batch_size=1,\n      gradient_accumulation_steps=4,\n      num_train_epochs=1,\n      learning_rate=2e-4,\n      fp16=True,\n#       save_total_limit=3,\n      save_steps=100,\n      logging_steps=1,\n      output_dir=\"experiments\",\n      optim=\"paged_adamw_8bit\",\n      lr_scheduler_type=\"cosine\",\n      warmup_ratio=0.05,\n)\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=data,\n    args=training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"trained_model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PEFT_MODEL = \"raya903/Healthcare-Chatbot\"\n\n# model.push_to_hub(PEFT_MODEL, use_auth_token='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')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:44:52.561047Z","iopub.execute_input":"2023-10-29T05:44:52.561432Z","iopub.status.idle":"2023-10-29T05:44:52.565825Z","shell.execute_reply.started":"2023-10-29T05:44:52.561389Z","shell.execute_reply":"2023-10-29T05:44:52.564846Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"config = PeftConfig.from_pretrained(PEFT_MODEL)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\ntokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = PeftModel.from_pretrained(model, PEFT_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:44:53.969481Z","iopub.execute_input":"2023-10-29T05:44:53.970228Z","iopub.status.idle":"2023-10-29T05:47:06.638526Z","shell.execute_reply.started":"2023-10-29T05:44:53.970198Z","shell.execute_reply":"2023-10-29T05:47:06.637731Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)/adapter_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490ee4bfe8364e76817e3f9dc0a4cf32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0daf9915dbec4a20b73f34e6de324c95"}},"metadata":{}},{"name":"stderr","text":"Some weights of FalconForCausalLM were not initialized from the model checkpoint at vilsonrodrigues/falcon-7b-instruct-sharded and are newly initialized: ['lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89c535ac60b24bbeba96d37e01cb0c2e"}},"metadata":{}}]},{"cell_type":"code","source":"generation_config = model.generation_config\ngeneration_config.max_new_tokens = 200\ngeneration_config.temperature = 0.7\ngeneration_config.top_p = 0.7\ngeneration_config.num_return_sequences = 1\ngeneration_config.pad_token_id = tokenizer.eos_token_id\ngeneration_config.eos_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:47:12.912647Z","iopub.execute_input":"2023-10-29T05:47:12.913272Z","iopub.status.idle":"2023-10-29T05:47:12.921599Z","shell.execute_reply.started":"2023-10-29T05:47:12.913238Z","shell.execute_reply":"2023-10-29T05:47:12.920555Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def infer(input):\n    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.inference_mode():\n       outputs = model.generate(\n         input_ids = encoding.input_ids,\n         attention_mask = encoding.attention_mask,\n         generation_config = generation_config\n       )\n\n    return (tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:03:18.985302Z","iopub.execute_input":"2023-10-29T06:03:18.985771Z","iopub.status.idle":"2023-10-29T06:03:18.992118Z","shell.execute_reply.started":"2023-10-29T06:03:18.985736Z","shell.execute_reply":"2023-10-29T06:03:18.991124Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def postprocess(response):\n    ans = response.split('.')\n    new_ans = []\n    for sent in ans:\n        if sent not in new_ans:\n            new_ans.append(sent)\n    new_response = '.'.join(new_ans)\n    print(new_response)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:03:20.316097Z","iopub.execute_input":"2023-10-29T06:03:20.316477Z","iopub.status.idle":"2023-10-29T06:03:20.322101Z","shell.execute_reply.started":"2023-10-29T06:03:20.316445Z","shell.execute_reply":"2023-10-29T06:03:20.321099Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"%%time\ndevice = \"cuda:0\"\nprompt = \"\"\"\n<human>: I woke up today and I am not feeling well.What should i do?\n<assistant>:\n\"\"\".strip()\n\npostprocess(infer(prompt))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:04:29.580084Z","iopub.execute_input":"2023-10-29T06:04:29.580997Z","iopub.status.idle":"2023-10-29T06:05:45.985312Z","shell.execute_reply.started":"2023-10-29T06:04:29.580964Z","shell.execute_reply":"2023-10-29T06:05:45.984308Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"<human>: I woke up today and I am not feeling well.What should i do?\n<assistant>: Hi, I have gone through your query. I can understand your concern. You have a viral infection. You should take rest and drink plenty of fluids. You can take over-the-counter pain relievers like acetaminophen or ibuprofen. You can also take paracetamol. If your symptoms persist, you should consult a doctor. Hope this helps. Take care. Stay healthy. Chat Doctor.  Take care.\nCPU times: user 1min 16s, sys: 0 ns, total: 1min 16s\nWall time: 1min 16s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ndevice = \"cuda:0\"\nprompt = \"\"\"\n<human>: I am feeling feverish. what should I do?\n<assistant>:\n\"\"\".strip()\n\npostprocess(infer(prompt)) ","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:12:44.546000Z","iopub.execute_input":"2023-10-29T06:12:44.546910Z","iopub.status.idle":"2023-10-29T06:14:00.690356Z","shell.execute_reply.started":"2023-10-29T06:12:44.546875Z","shell.execute_reply":"2023-10-29T06:14:00.689477Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"<human>: I am feeling feverish. what should I do?\n<assistant>: Hi, I have gone through your query. I can understand your concern. You are having fever. You should take antipyretic medicine and drink plenty of fluids. You can take paracetamol (acetaminophen) 500 mg three times a day. You can also take ibuprofen (Advil) 200 mg three times a day. You should also take rest and avoid any strenuous work. If your fever persists, you should consult a doctor. Hope this helps. Take care. Stay healthy. Chat Doctor.  Take care. \nCPU times: user 1min 16s, sys: 0 ns, total: 1min 16s\nWall time: 1min 16s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ndevice = \"cuda:0\"\nprompt = \"\"\"\n<human>: I have a headache and I am feeling nauseous. what should I do?\n<assistant>:\n\"\"\".strip()\npostprocess(infer(prompt))       ","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:15:03.308396Z","iopub.execute_input":"2023-10-29T06:15:03.309361Z","iopub.status.idle":"2023-10-29T06:16:18.339618Z","shell.execute_reply.started":"2023-10-29T06:15:03.309328Z","shell.execute_reply":"2023-10-29T06:16:18.338397Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"<human>: I have a headache and I am feeling nauseous. what should I do?\n<assistant>: Hi, Thanks for your query. I can understand your concern. You are suffering from headache and nausea. You can take over-the-counter pain relievers like acetaminophen or ibuprofen. You can also take over-the-counter anti-nausea medication like ondansetron or metoclopramide. You can also try taking a warm bath or applying a cold compress to your forehead. If your symptoms persist, you should consult a doctor. Hope this helps. Take care. Stay healthy. Chat Doctor.  Take care. \nCPU times: user 1min 14s, sys: 0 ns, total: 1min 14s\nWall time: 1min 15s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}